---
layout: post
title:      "CLI Scraper Project"
date:       2020-05-08 21:28:51 +0000
permalink:  cli_scraper_project
---


The inspiration for my project came from a problem my family has almost every other night: What are we going to eat for dinner? Often we have plenty of food on hand, but no clear goal of what to make with it all. We could always stick to a few standby recipes - make a pot of rice, fry some veggies and call it stir-fry! Cook any protein and serve it with pasta and sauce, etc. - but over time that gets boring. I've sometimes been left paralyzed by indecision for so long I end up just ordering out. Sometimes I would love to just be told what to cook, instead of trying to get creative at the end of the day.

I'm sure I'm not alone in this phenomenon, and looking at all of us collectively, there's a huge potential for lots of food to go to waste. [According to the USDA](https://www.usda.gov/foodwaste/faqs), food waste is estimated at between 30-40 percent of the food supply. We can't continue letting fresh produce go to waste because we're too lazy, busy, tired, or anything else to make sure we use what we've bought before it goes bad. Having a means of keeping inventory on what you have and being able to search for recipes based on your current pantry items could be a great way to monitor and reduce your food waste.

Thus I set out to create a CLI app that would be able to display a random recipe to cut through the indecision, and also give the chance to search recipes based on what ingredients you had on hand. Typically when I search for recipes, I find that the food network has some of the top results, and they don't suffer from having pages of personal anecdotes that precede most other recipe blogs, giving only the relevant information. I decided to scrape data from their site, particularly the A-Z index of recipes. 

The pages are set up so each recipe, and each ingredient or instruction all use the same CSS class, so that made it easy to iterate through and grab all the information needed to populate the database. The scraper class has three instance methods, each operating on a deeper level of the page hierarchy. The first method reaches through each of the alphabetic indices. The second layer scans the pages returned from the first and grabs links to each individual recipe's page. The final method is where the bulk of the work is done: the scraper creates a recipe based on the title, scans the ingredient list and parses the information, separating the name of the item and the quantity, and then stores each step of the instructions inside the recipe.

The scraper takes quite a while to work, even loading only the recipes from one letter index takes three minutes or more. When I tried loading every page of the index, it took upwards of an hour. I'm interested in learning more about how to make data scraping more efficient, since ideally you would want a user to be able to quickly load the app and ask for a recipe much faster than this. From reading more, I think it may be that I'm first calling open on the index, then on the recipe list, then again on the recipe itself, so all of my major operations are happening while keeping open three nokogiri pages at the same time. I might try to refactor these methods to close the irrelevant ones and see if that speeds up the program.

One of the big issues I came up against when scraping was the food network website itself. Each page of the alphabetical index would have multiple pages of recipes, but the "next page" links were all broken! So I could only grab the first 150 or so recipes in each letter. Further, some of the recipe pages also had broken links, causing a lot of errors with open-uri. Upon googling the errors, I found one solution that rescued the redirect exception that open-uri throws in cases of 404s or infinitely redirecting links. As I kept reading, there was an interesting discussion on the use of error throws and exceptions in place of better and more robust logic. In an ideal case, the app wouldn't be working correctly *because* an error was thrown, but because it was designed well. Rescuing the error to work around an issue instead of outright solving the issue is inelegant, and a bit of a "code smell". I tried several other options that were suggested, but none seemed to work and so I stuck with the less-than-ideal but functional way. Regardless, I learned a lot about open-uri from the reading and debugging.

With the scraper correctly reading the information, my next task was to parse that information in a way that was convenient for my code. The title and instructions were easy enough to figure out, as I was simply grabbing the information and displaying it back in my CLI. The ingredients were much trickier. Food Network had my back a bit more on this one, as the ingredients mostly followed the same format. Even then, there were interesting issues to work around. The most basic ingredients had no information about quantity and I could give their ingredient object the full string as a name, for example, "Salt and black pepper, to taste". The next easiest variety were the whole ingredients in greater quantities, things like "3 oranges". Next were items with clear measurements: teaspoons, tablespoons, pounds, etc. It took a few trials to expand the list of words to include as many common measurements as possible, as well as fitting the regex to account for whole and fractional quantities. I chose to leave out more subjective measuring terms, like bunches, cloves, handfuls, heaping scoops, etc. The parsing was done in such a way that any outlying ingredients, weird edge cases, or major typos would still make as much sense as possible. "2 cloves of garlic" might ideally have become "2 cloves" of "garlic", but instead would be "2" "cloves of garlic". While not perfect, it's still legible.

A greater challenge that I chose not to try (instead opting to let the user search based on keywords) would be to account for adjectives that differentiated types of a similar ingredient. For example, it would be cool to have all instances of "tomatoes" "cherry tomatoes" and "plum tomatoes" refer to the same tomato object (of class Ingredient). This raises a lot of sometimes subjective questions that would be hard to answer in code. Is a CherryTomato a subclass of a Tomato, or a Cherry? How would you programmatically decide which item was the ingredient and which the description?

The object relationship here is interesting, as it's a many-to-many setup. Recipes each have many Ingredients, but those ingredients might be used in many different recipes (i.e. tons of recipes call for rice, and each of them requires more than just rice). Thus I created an abstract intermediate class of RecipeIngredient. This class holds the links between the two other classes. It's easiest to think of these as "An Ingredient's use within a particular Recipe" so an example would be "Flour for Cookies" or "Flour for Cake". This intermediate class holds the single source of truth as well; when a recipe lists its ingredients, it doesn't have its own list that might be inaccurate, it instead has to seek through RecipeIngredient for all the links connected to itself and then see what ingredients are held there.



As I was working on this project, I kept thinking of even cooler ways to create an app like this that extends to all sorts of different resources. One thought I had was to create links between different ingredients that offered substitutions. It'd be a cool way for recipes to be modified to be gluten-free, or vegan, or to reduce the sugar or sodium content, etc. It'd also make sense to link such an app to other popular apps like Instacart, so that if you searched for recipes based on what you have, you could automatically order the missing ingredients. Sticking with the goal of food waste reduction, the app could record when you purchased certain items and give you notifications when they were nearing their expiration date. Users could connect the app to calorie-tracking apps and automatically record the meals they eat. I'm excited to try making that a reality some day!
